{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un resumen de la interfaz Estimator de scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Scikit-learn ofrece una interfaz uniforme para todos sus algoritmos de aprendizaje automático. Dado un *estimador* de scikit-learn, cuya instancia se denomina `model`, los siguientes métodos estarían disponibles:\n",
    "\n",
    "- Disponibles en **todos los estimadores**\n",
    "  + `model.fit()`: ajusta los datos de entrenamiento. Para aplicaciones de aprendizaje supervisado, este método recibe dos parámetros: los datos `X` y las etiquetas `y` (p.ej. `model.fit(X, y)`). Para aplicaciones no supervisadas, `fit` recibe un único argumento, los datos `X` (p.ej. `model.fit(X)`).\n",
    "  \n",
    "  \n",
    "- Disponible en **estimadores supervisados**\n",
    "  + `model.predict()`: dado un modelo que ya está entrenado, predice la etiqueta de un nuevo conjunto de datos. Este método acepta un único argumento, los nuevos datos `X_new` (p.ej. `model.predict(X_new)`) y devuelve la etiqueta predicha para ejemplo de la matriz.\n",
    "  + `model.predict_proba()`: para problemas de clasificación, algunos estimadores también tienen este método, que devuelve la probabilidad de que cada patrón pertenezca a cada una de las categorías a predecir. La categoría con máxima probabilidad coincidiría con la etiqueta predicha por `model.predict()`.\n",
    "  + `model.decision_function()`: para problemas de clasificación, algunos estimadores proporcionan una estimación de incertidumbre que no es una probabilidad. Para clasificación binaria, la función decision_function >= 0 significa que se predice clase positiva, mientras que decision_function < 0 significa que se predice clase negativa.\n",
    "  + `model.score()`: para problemas de clasificación o de regresión, casi todos los estimadores implementan un método de puntuación.  Las puntuaciones tienen que estar entre 0 y 1, y la bondad del estimador debería ser más alta cuanto mayor es su puntuación. Para clasificadores, el método `score` está asociado al porcentaje de patrones bien clasificados. Para regresores, `score` devuelvo el coeficiente de determinación (R<sup>2</sup>) de la predicción.\n",
    "  + `model.transform()`: para los algoritmos de selección de características, este método reducirá el dataset dejando sólo las columnas (características) seleccionadas. Para algunos modelos de clasificación y regresión como los modelos lineales o los bosques aleatorios (*random forests*), este método deja sólo las características más informativas. De esta forma, estos algoritmos de clasificación o de regresión pueden usarse como métodos de selección de características.\n",
    "  \n",
    "  \n",
    "- Disponible en **estimadores no supervisados**\n",
    "  + `model.transform()`: dado un modelo no supervisado, transforma nuevos datos según el modelo. Acepta un único argumento `X_new` y devuelve la nueva representación de los datos.\n",
    "  + `model.fit_transform()`: algunos estimadores implementan este método que realiza de forma más eficiente el ajuste y transformación sobre el mismo conjunto de datos que realizar, secuencialmente, una llamada a `model.fit(X)` y después a `model.transform(X)`.\n",
    "  + `model.predict()`: si se trata de un algoritmo de agrupamiento, este método nos predecirá las etiquetas de grupo asignadas a nuevos puntos. No todos los algoritmos de agrupamiento pueden aplicarse a nuevos datos tras el proceso de *clustering*.\n",
    "  + `model.predict_proba()`: los modelos de mixturas Gaussianas (*Gaussian mixture models*, GMMs) proporcionan la probabilidad de que cada punto haya sido generado por cada uno de los componentes de la mixtura.\n",
    "  + `model.score()`: los modelos basados en densidades como *Kernel Density Estimation* (KDE) y los GMMs nos permiten obtener la verosimilitud de los datos según el ajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Además de ``fit``, las dos funciones más importantes son ``predict`` para producir una respuesta aproximada (una ``y``) y ``transform`` para obtener una nueva representación de los datos (una nueva ``X``). La siguiente tabla muestra para que clase de modelo se aplica cada función:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr style=\"border:None; font-size:20px; padding:10px;\"><th>``model.predict``</th><th>``model.transform``</th></tr>\n",
    "<tr style=\"border:None; font-size:15px; padding:10px;\"><td>Clasificación</td><td>Preprocesamiento</td></tr>\n",
    "<tr style=\"border:None; font-size:15px; padding:10px;\"><td>Regresión</td><td>Reducción de la dimensionalidad</td></tr>\n",
    "<tr style=\"border:None; font-size:15px; padding:10px;\"><td>Agrupamiento</td><td>Extracción de características</td></tr>\n",
    "<tr style=\"border:None; font-size:15px; padding:10px;\"><td>&nbsp;</td><td>Selección de características</td></tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
