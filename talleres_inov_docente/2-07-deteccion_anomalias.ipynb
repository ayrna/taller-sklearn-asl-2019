{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de anomalías\n",
    "\n",
    "La detección de anomalías (*anomaly detection*, AD) es una tarea de aprendizaje automático que consiste en detectar *outliers* o datos fuera de rango.\n",
    "\n",
    "*An outlier is an observation in a data set which appears to be inconsistent with the remainder of that set of data.*\n",
    "Johnson 1992\n",
    "\n",
    "*An outlier is an observation which deviates so much from the other observations as to arouse suspicions that it was generated by a different mechanism.*\n",
    "  Outlier/Anomaly\n",
    "Hawkins 1980\n",
    "\n",
    "## Tipos de entornos en los que se produce la detección de anomalías\n",
    "\n",
    "- AD supervisada\n",
    "\n",
    "    - Las etiquetas están disponibles, tanto para casos normales como para casos anómalos.\n",
    "    - En cierto modo, similar a minería de clases poco comunes o clasificación no balanceada.\n",
    "    \n",
    "    \n",
    "    \n",
    "- AD Semi-supervisada (detección de novedades, *Novelty Detection*)\n",
    "\n",
    "    - Durante el entrenamiento, solo tenemos datos normales.\n",
    "    - El algoritmo aprende únicamente usando los datos normales.\n",
    "    \n",
    "    \n",
    "    \n",
    "- AD no supervisada (detección de outliers, *Outlier Detection*)\n",
    "\n",
    "    - No hay etiquetas y el conjunto de entrenamiento tiene datos normales y datos anómalos.\n",
    "    - Asunción: los datos anómalos son poco frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a familiarizarnos con la detección de anomalías no supervisada. Para visualizar la salida de los distintos algoritmos, vamos a considerar un dataset bidimensional que consiste en una mixtura de Gaussianas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generando el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_features=2, centers=3, n_samples=500,\n",
    "                  random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de anomalías con estimación de densidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "# Estimador de densidad Gaussiano\n",
    "kde = KernelDensity(kernel='gaussian')\n",
    "kde = kde.fit(X)\n",
    "kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_X = kde.score_samples(X)\n",
    "print(kde_X.shape)  # nos proporciona la verosimilitud de los datos. Cuanto más baja, más anómalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import mquantiles\n",
    "alpha_set = 0.95\n",
    "tau_kde = mquantiles(kde_X, 1. - alpha_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape\n",
    "X_range = np.zeros((n_features, 2))\n",
    "X_range[:, 0] = np.min(X, axis=0) - 1.\n",
    "X_range[:, 1] = np.max(X, axis=0) + 1.\n",
    "\n",
    "h = 0.1  # Tamaño de paso de la rejilla\n",
    "x_min, x_max = X_range[0]\n",
    "y_min, y_max = X_range[1]\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z_kde = kde.score_samples(grid)\n",
    "Z_kde = Z_kde.reshape(xx.shape)\n",
    "\n",
    "plt.figure()\n",
    "c_0 = plt.contour(xx, yy, Z_kde, levels=tau_kde, colors='red', linewidths=3)\n",
    "plt.clabel(c_0, inline=1, fontsize=15, fmt={tau_kde[0]: str(alpha_set)})\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema de usar la estimación de densidad es que es ineficiente cuando la dimensionalidad de los datos es demasiado alta. El algoritmo *one-class SVM* si que puede utilizarse en estos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 0.05  # Resultados teóricos dicen que hay un 5% de datos anómalos\n",
    "ocsvm = OneClassSVM(kernel='rbf', gamma=0.05, nu=nu)\n",
    "ocsvm.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_outliers = X[ocsvm.predict(X) == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Z_ocsvm = ocsvm.decision_function(grid)\n",
    "Z_ocsvm = Z_ocsvm.reshape(xx.shape)\n",
    "\n",
    "plt.figure()\n",
    "c_0 = plt.contour(xx, yy, Z_ocsvm, levels=[0], colors='red', linewidths=3)\n",
    "plt.clabel(c_0, inline=1, fontsize=15, fmt={0: str(alpha_set)})\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.scatter(X_outliers[:, 0], X_outliers[:, 1], color='red')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectores soporte o outliers\n",
    "\n",
    "En el one-class SVM, no todos los vectores soporte son outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_SV = X[ocsvm.support_]\n",
    "n_SV = len(X_SV)\n",
    "n_outliers = len(X_outliers)\n",
    "\n",
    "print('{0:.2f} <= {1:.2f} <= {2:.2f}?'.format(1./n_samples*n_outliers, nu, 1./n_samples*n_SV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo los vectores soporte sirven a la hora de calcular la función de decisión del One-Class SVM.\n",
    "\n",
    "Ahora vamos a representar la función de decisión del One-Class SVM como hicimos con la densidad y vamos a marcar los vectores soporte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.contourf(xx, yy, Z_ocsvm, 10, cmap=plt.cm.Blues_r)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=1.)\n",
    "plt.scatter(X_SV[:, 0], X_SV[:, 1], color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EJERCICIO</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      **Cambia** el parámetro `gamma` y comprueba como afecta la función de decisión.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Isolation Forest*\n",
    "\n",
    "El algoritmo *Isolation Forest* es un algoritmo de AD basado en árboles. Construye un determinado número de árboles aleatorios y su idea principal es que si un ejemplo es una anomalía, entonces debería aparecer aislado en la hoja de un árbol tras algunas particiones. El *Isolation Forest* deriva una puntuación de anormalidad basada en la profundidad del árbol en la cuál términos los ejemplos anómalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iforest = IsolationForest(n_estimators=300, contamination=0.10)\n",
    "iforest = iforest.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Z_iforest = iforest.decision_function(grid)\n",
    "Z_iforest = Z_iforest.reshape(xx.shape)\n",
    "\n",
    "plt.figure()\n",
    "c_0 = plt.contour(xx, yy, Z_iforest,\n",
    "                  levels=[iforest.threshold_],\n",
    "                  colors='red', linewidths=3)\n",
    "plt.clabel(c_0, inline=1, fontsize=15,\n",
    "           fmt={iforest.threshold_: str(alpha_set)})\n",
    "plt.scatter(X[:, 0], X[:, 1], s=1.)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EJERCICIO</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Ilustra gráficamente la influencia del número de árboles en la suavidad de la función de decisión\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Aplicación al dataset de dígitos\n",
    "\n",
    "Ahora vamos a aplicar el ``IsolationForest`` para intentar localizar dígitos que han sido escritos de modo poco convencional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de datos de dígitos consiste en imágenes de 8x8 valores de gris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = digits.images\n",
    "labels = digits.target\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 102\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.title('{0}'.format(labels[i]))\n",
    "plt.axis('off')\n",
    "plt.imshow(images[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar las imágenes como patrones de entrenamiento, tenemos que pasarlas a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a centrarnos en el dígito 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_5 = X[y == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(10, 4))\n",
    "for ax, x in zip(axes, X_5[:5]):\n",
    "    img = x.reshape(8, 8)\n",
    "    ax.imshow(img, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar ``IsolationForest`` para encontrar el 5% de imágenes más anómalas y representarlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "iforest = IsolationForest(contamination=0.05)\n",
    "iforest = iforest.fit(X_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos el grado de anormalidad utilizando `iforest.decision_function`. Cuanto más bajo, más anómalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest_X = iforest.decision_function(X_5)\n",
    "plt.hist(iforest_X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dibujemos los 10 ejemplos más \"normales\" (*inliers*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_strong_inliers = X_5[np.argsort(iforest_X)[-10:]]\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "\n",
    "for i, ax in zip(range(len(X_strong_inliers)), axes.ravel()):\n",
    "    ax.imshow(X_strong_inliers[i].reshape((8, 8)),\n",
    "               cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a dibujar los *outliers*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "\n",
    "X_outliers = X_5[iforest.predict(X_5) == -1]\n",
    "\n",
    "for i, ax in zip(range(len(X_outliers)), axes.ravel()):\n",
    "    ax.imshow(X_outliers[i].reshape((8, 8)),\n",
    "               cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EJERCICIO</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Haz lo mismo pero para los dígitos 9 y 7.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
